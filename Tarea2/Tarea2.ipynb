{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88441fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18815/875304723.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clean['Payment Method'] = pm.map(lambda x: mapping.get(x)).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leído: Data/Dataset.csv\n",
      "Filas antes: 150000\n",
      "Filas después (sin nulos): 93000\n",
      "Archivo limpio guardado en: Data/Dataset_clean.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "src =  \"Data/Dataset.csv\"\n",
    "dst =  \"Data/Dataset_clean.csv\"\n",
    "\n",
    "df = pd.read_csv(src)\n",
    "before = len(df)\n",
    "\n",
    "# Columnas a mantener\n",
    "cols = [\n",
    "\t\"Vehicle Type\",\n",
    "\t\"Avg VTAT\",\n",
    "\t\"Avg CTAT\",\n",
    "\t\"Booking Value\",\n",
    "\t\"Ride Distance\",\n",
    "\t\"Driver Ratings\",\n",
    "\t\"Customer Rating\",\n",
    "\t\"Payment Method\",\n",
    "]\n",
    "\n",
    "# Seleccionar solo las columnas solicitadas \n",
    "existing_cols = [c for c in cols if c in df.columns]\n",
    "df_sub = df[existing_cols].copy()\n",
    "\n",
    "# Eliminar filas con nulos en las columnas retenidas\n",
    "df_clean = df_sub.dropna(how=\"any\")\n",
    "after = len(df_clean)\n",
    "\n",
    "# Transformar la columna categórica 'Payment Method' a numérica 0..N-1\n",
    "# Mapeo determinista: ordenar categorías y asignar 0..N-1\n",
    "pm = df_clean['Payment Method'].astype(str)\n",
    "unique = sorted(pm.unique())\n",
    "mapping = {cat: i for i, cat in enumerate(unique)}\n",
    "df_clean['Payment Method'] = pm.map(lambda x: mapping.get(x)).astype(int)\n",
    "\n",
    "# Guardar mapping para referencia\n",
    "map_path = 'payment_method_mapping.csv'\n",
    "pd.Series(mapping).rename('code').to_csv(map_path)\n",
    "\n",
    "\t\n",
    "\n",
    "df_clean.to_csv(dst, index=False)\n",
    "\n",
    "print(f\"Leído: {src}\")\n",
    "print(f\"Filas antes: {before}\")\n",
    "print(f\"Filas después (sin nulos): {after}\")\n",
    "print(f\"Archivo limpio guardado en: {dst}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0901f69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Análisis del dataset ==\n",
      "Dataset shape: (93000, 8)\n",
      "Columns: ['Vehicle Type', 'Avg VTAT', 'Avg CTAT', 'Booking Value', 'Ride Distance', 'Driver Ratings', 'Customer Rating', 'Payment Method']\n",
      "Dtypes:\n",
      " Vehicle Type        object\n",
      "Avg VTAT           float64\n",
      "Avg CTAT           float64\n",
      "Booking Value      float64\n",
      "Ride Distance      float64\n",
      "Driver Ratings     float64\n",
      "Customer Rating    float64\n",
      "Payment Method       int64\n",
      "dtype: object\n",
      "Head:\n",
      "    Vehicle Type  Avg VTAT  Avg CTAT  Booking Value  Ride Distance  \\\n",
      "0           Auto      13.4      25.8          627.0          13.58   \n",
      "1  Premier Sedan      13.1      28.5          416.0          34.02   \n",
      "2           Bike       5.3      19.6          737.0          48.21   \n",
      "3           Auto       5.1      18.1          316.0           4.85   \n",
      "4        Go Mini       7.1      20.4          640.0          41.24   \n",
      "\n",
      "   Driver Ratings  Customer Rating  Payment Method  \n",
      "0             4.9              4.9               2  \n",
      "1             4.6              5.0               3  \n",
      "2             4.1              4.3               3  \n",
      "3             4.1              4.6               3  \n",
      "4             4.0              4.1               3  \n",
      "\n",
      "== Resultados (Silhouette en train) ==\n",
      "ms_bw_q0.1: meanshift bw=2.512, silhouette=0.516895, clusters=2\n",
      "kmeans_random_k2: kmeans k=2, silhouette=0.141679, clusters=2\n",
      "kmeanspp_k2: kmeans++ k=2, silhouette=0.141679, clusters=2\n",
      "kmeans_random_k5: kmeans k=5, silhouette=0.125178, clusters=5\n",
      "kmeanspp_k5: kmeans++ k=5, silhouette=0.125155, clusters=5\n",
      "kmeans_random_k4: kmeans k=4, silhouette=0.121305, clusters=4\n",
      "kmeanspp_k4: kmeans++ k=4, silhouette=0.121259, clusters=4\n",
      "kmeans_random_k3: kmeans k=3, silhouette=0.116904, clusters=3\n",
      "kmeanspp_k3: kmeans++ k=3, silhouette=0.116879, clusters=3\n",
      "ms_bw_q0.2: meanshift bw=2.894, silhouette=-1.000000, clusters=1\n",
      "ms_bw_q0.3: meanshift bw=3.166, silhouette=-1.000000, clusters=1\n",
      "ms_bw_med_scaled: meanshift bw=4.341, silhouette=-1.000000, clusters=1\n",
      "\n",
      "== Top 3 seleccionadas ==\n",
      "1. ms_bw_q0.1 (meanshift, bw=2.512) -> silhouette=0.516895, clusters=2\n",
      "2. kmeans_random_k2 (kmeans, k=2) -> silhouette=0.141679, clusters=2\n",
      "3. kmeanspp_k2 (kmeans++, k=2) -> silhouette=0.141679, clusters=2\n",
      "\n",
      "Resumen guardado en: results/cluster_eval_summary.txt\n",
      "Archivos CSV de comparación guardados en: results/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# === Análisis inicial del dataset ===\n",
    "def analyze_dataset(df: pd.DataFrame) -> None:\n",
    "    print('Dataset shape:', df.shape)\n",
    "    print('Columns:', list(df.columns))\n",
    "    print('Dtypes:\\n', df.dtypes)\n",
    "    print('Head:')\n",
    "    print(df.head(5))\n",
    "\n",
    "\n",
    "# === División en variables X / y ===\n",
    "def split_features(df: pd.DataFrame):\n",
    "    label_col = 'Vehicle Type'\n",
    "    y = df[label_col].copy()\n",
    "    X = df.drop(columns=[label_col]).select_dtypes(include=[np.number]).copy()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# === Configuraciones de KMeans ===\n",
    "def build_kmeans_random_configs():\n",
    "    return [\n",
    "        {'algo': 'kmeans', 'name': f'kmeans_random_k{k}', 'n_clusters': k, 'init': 'random', 'n_init': 10, 'random_state': 42}\n",
    "        for k in [2, 3, 4, 5]\n",
    "    ]\n",
    "\n",
    "\n",
    "def build_kmeanspp_configs():\n",
    "    return [\n",
    "        {'algo': 'kmeans++', 'name': f'kmeanspp_k{k}', 'n_clusters': k, 'init': 'k-means++', 'n_init': 10, 'random_state': 42}\n",
    "        for k in [2, 3, 4, 5]\n",
    "    ]\n",
    "\n",
    "\n",
    "# === Configuraciones de MeanShift ===\n",
    "def build_meanshift_configs(X_train: np.ndarray):\n",
    "    sample_size = min(5000, X_train.shape[0])\n",
    "    quantiles = [0.1, 0.2, 0.3]\n",
    "    configs = [\n",
    "        {'algo': 'meanshift', 'name': f'ms_bw_q{q}', 'bandwidth': float(estimate_bandwidth(X_train, quantile=q, n_samples=sample_size))}\n",
    "        for q in quantiles\n",
    "    ]\n",
    "    bws = [c['bandwidth'] for c in configs]\n",
    "    med = float(np.median(bws))\n",
    "    configs.append({'algo': 'meanshift', 'name': 'ms_bw_med_scaled', 'bandwidth': med * 1.5})\n",
    "    return configs[:4]\n",
    "\n",
    "# === Evaluación de configuración (versión corregida) ===\n",
    "def eval_config(X_train: np.ndarray, cfg: dict):\n",
    "    if cfg['algo'] in ('kmeans', 'kmeans++'):\n",
    "        model = KMeans(\n",
    "            n_clusters=cfg['n_clusters'],\n",
    "            init=cfg['init'],\n",
    "            n_init=10,\n",
    "            max_iter=300,\n",
    "            tol=1e-4,\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        model = MeanShift(bandwidth=cfg['bandwidth'], bin_seeding=True, n_jobs=-1)\n",
    "\n",
    "    labels = model.fit_predict(X_train)\n",
    "    n_clusters = len(np.unique(labels))\n",
    "\n",
    "    # Caso 1 cluster\n",
    "    if n_clusters < 2:\n",
    "        score = -1\n",
    "    else:\n",
    "        score = silhouette_score(X_train, labels)\n",
    "\n",
    "    return score, cfg | {'model': model}, labels\n",
    "\n",
    "\n",
    "# === Mapeo de etiquetas dominantes ===\n",
    "def dominant_label_map(train_labels: np.ndarray, y_train: pd.Series):\n",
    "    mapping = {}\n",
    "    y_vals = y_train.reset_index(drop=True)\n",
    "    for c in np.unique(train_labels):\n",
    "        vals = y_vals[train_labels == c]\n",
    "        if len(vals) > 0:\n",
    "            mapping[int(c)] = vals.mode(dropna=True).iloc[0]\n",
    "    return mapping\n",
    "\n",
    "\n",
    "# === Ejecución ===\n",
    "path = \"Data/Dataset_clean.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "print('== Análisis del dataset ==')\n",
    "analyze_dataset(df)\n",
    "\n",
    "X_df, y = split_features(df)\n",
    "X_train_df, X_test_df, y_train, y_test = train_test_split(\n",
    "    X_df, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_df.values)\n",
    "X_test = scaler.transform(X_test_df.values)\n",
    "\n",
    "# Configuraciones (4 por algoritmo)\n",
    "km_random_cfgs = build_kmeans_random_configs()\n",
    "kmpp_cfgs = build_kmeanspp_configs()\n",
    "ms_cfgs = build_meanshift_configs(X_train)\n",
    "all_cfgs = km_random_cfgs + kmpp_cfgs + ms_cfgs\n",
    "\n",
    "# Evaluación de configuraciones\n",
    "evaluated = [eval_config(X_train, cfg) for cfg in all_cfgs]\n",
    "evaluated.sort(key=lambda t: t[0], reverse=True)\n",
    "\n",
    "print('\\n== Resultados (Silhouette en train) ==')\n",
    "for score, cfg, labels in evaluated:\n",
    "    if cfg['algo'] in ('kmeans', 'kmeans++'):\n",
    "        print(f\"{cfg['name']}: {cfg['algo']} k={cfg['n_clusters']}, silhouette={score:.6f}, clusters={len(np.unique(labels))}\")\n",
    "    else:\n",
    "        print(f\"{cfg['name']}: meanshift bw={cfg['bandwidth']:.3f}, silhouette={score:.6f}, clusters={len(np.unique(labels))}\")\n",
    "\n",
    "# Top 3\n",
    "top3 = evaluated[:3]\n",
    "print('\\n== Top 3 seleccionadas ==')\n",
    "for i, (score, cfg, labels) in enumerate(top3, 1):\n",
    "    extra = f\"k={cfg['n_clusters']}\" if cfg['algo'] in ('kmeans', 'kmeans++') else f\"bw={cfg['bandwidth']:.3f}\"\n",
    "    print(f\"{i}. {cfg['name']} ({cfg['algo']}, {extra}) -> silhouette={score:.6f}, clusters={len(np.unique(labels))}\")\n",
    "\n",
    "# === Evaluación en test ===\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "summary_path = \"results/cluster_eval_summary.txt\"\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write('Resultados de las 12 configuraciones (ordenadas por silhouette en train)\\n')\n",
    "    for score, cfg, labels in evaluated:\n",
    "        extra = f\"k={cfg['n_clusters']}\" if cfg['algo'] in ('kmeans', 'kmeans++') else f\"bw={cfg['bandwidth']:.3f}\"\n",
    "        f.write(f\"{cfg['name']}: {cfg['algo']} {extra}, silhouette={score:.6f}, clusters={len(np.unique(labels))}\\n\")\n",
    "\n",
    "    f.write('\\nTop 3 globales:\\n')\n",
    "    for i, (score, cfg, labels) in enumerate(top3, 1):\n",
    "        extra = f\"k={cfg['n_clusters']}\" if cfg['algo'] in ('kmeans', 'kmeans++') else f\"bw={cfg['bandwidth']:.3f}\"\n",
    "        f.write(f\"{i}. {cfg['name']} ({cfg['algo']}, {extra}) -> silhouette={score:.6f}, clusters={len(np.unique(labels))}\\n\")\n",
    "\n",
    "# === Comparación de etiquetas en test ===\n",
    "for score, cfg, train_labels in top3:\n",
    "    model = cfg['model']\n",
    "    dom_map = dominant_label_map(train_labels, y_train)\n",
    "    test_clusters = model.predict(X_test)\n",
    "\n",
    "    rows = []\n",
    "    matches = 0\n",
    "    total = len(X_test_df)\n",
    "\n",
    "    for idx, c in zip(X_test_df.index, test_clusters):\n",
    "        dominant = dom_map.get(int(c))\n",
    "        real_y = y_test.loc[idx]\n",
    "        match = (real_y == dominant)\n",
    "        if match:\n",
    "            matches += 1\n",
    "        rows.append({\n",
    "            'index': idx,\n",
    "            'pred_cluster': int(c),\n",
    "            'dominant_train_label_for_cluster': dominant,\n",
    "            'real_Y': real_y,\n",
    "            'match': match,\n",
    "        })\n",
    "\n",
    "    acc = matches / total\n",
    "    comp_df = pd.DataFrame(rows).set_index('index')\n",
    "    comp_path = f\"results/{cfg['name']}_test_comparison.csv\"\n",
    "    comp_df.to_csv(comp_path)\n",
    "\n",
    "    with open(summary_path, 'a') as f:\n",
    "        f.write(f\"\\n=== {cfg['name']} ({cfg['algo']}) ===\\n\")\n",
    "        extra = f\"k={cfg['n_clusters']}\" if cfg['algo'] in ('kmeans', 'kmeans++') else f\"bandwidth={cfg['bandwidth']:.3f}\"\n",
    "        f.write(f\"{extra}\\nSilhouette train={score:.6f}\\n\")\n",
    "        f.write(f\"Dominant-label match accuracy on test={acc:.4f}\\n\")\n",
    "        f.write(f\"Detalle: {os.path.basename(comp_path)}\\n\")\n",
    "\n",
    "print(f\"\\nResumen guardado en: {summary_path}\")\n",
    "print(\"Archivos CSV de comparación guardados en: results/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b5a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Eliminada la peor config log_2\n",
      "Epoch 10: Eliminada la peor config svm_1\n",
      "Epoch 15: Eliminada la peor config svm_2\n",
      "Epoch 20: Eliminada la peor config svm_3\n",
      "\n",
      "=== Resultados finales ===\n",
      "\n",
      "Config log_1:\n",
      "{\n",
      "  \"accuracy\": 0.998978494623656,\n",
      "  \"precision\": 0.9988152934841141,\n",
      "  \"recall\": 0.9991381167851756,\n",
      "  \"f1\": 0.998976679054236\n",
      "}\n",
      "\n",
      "Config log_3:\n",
      "{\n",
      "  \"accuracy\": 0.9986021505376345,\n",
      "  \"precision\": 0.9988143996550981,\n",
      "  \"recall\": 0.9983839689722043,\n",
      "  \"f1\": 0.9985991379310345\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# === Carga de datos ===\n",
    "def load_data(path, max_rows=None):\n",
    "    df = pd.read_csv(path)\n",
    "    if max_rows:\n",
    "        df = df.head(max_rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "# === Preprocesamiento ===\n",
    "def preprocess(df):\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Etiqueta: valor alto de reserva (mayor que la mediana)\n",
    "    df['Booking Value'] = pd.to_numeric(df['Booking Value'], errors='coerce')\n",
    "    median_val = df['Booking Value'].median()\n",
    "    y = (df['Booking Value'] > median_val).astype(int)\n",
    "\n",
    "    num_cols = [\n",
    "        'Avg VTAT', 'Avg CTAT', 'Booking Value',\n",
    "        'Ride Distance', 'Driver Ratings',\n",
    "        'Customer Rating', 'Payment Method'\n",
    "    ]\n",
    "    for c in num_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    X_num = df[num_cols].fillna(0)\n",
    "\n",
    "    # Codificación de la variable categórica\n",
    "    X_cat = pd.get_dummies(df['Vehicle Type'].fillna('missing'), drop_first=True)\n",
    "\n",
    "    X_final = pd.concat([X_num, X_cat], axis=1)\n",
    "    return X_final.values, y.values\n",
    "\n",
    "\n",
    "# === Creación del modelo ===\n",
    "def make_model(config):\n",
    "    loss = 'log_loss' if config['technique'] == 'logistic' else 'hinge'\n",
    "    return SGDClassifier(\n",
    "        loss=loss,\n",
    "        learning_rate='constant',\n",
    "        eta0=config['eta0'],\n",
    "        alpha=config['alpha'],\n",
    "        max_iter=1,\n",
    "        tol=None,\n",
    "        random_state=config['random_state'],\n",
    "        warm_start=True\n",
    "    )\n",
    "\n",
    "\n",
    "# === Evaluación ===\n",
    "def evaluate_model(model, scaler, X_test, y_test):\n",
    "    Xs = scaler.transform(X_test)\n",
    "    preds = model.predict(Xs)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, preds),\n",
    "        'precision': precision_score(y_test, preds, zero_division=0),\n",
    "        'recall': recall_score(y_test, preds, zero_division=0),\n",
    "        'f1': f1_score(y_test, preds, zero_division=0)\n",
    "    }\n",
    "\n",
    "\n",
    "# === Entrenamiento con eliminación progresiva ===\n",
    "def run_training(configs, X_train, y_train, X_val, y_val):\n",
    "    active = {c['id']: {'config': c, 'history': []} for c in configs}\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    eval_interval = 5\n",
    "    max_epochs = max(c['max_epochs'] for c in configs)\n",
    "\n",
    "    models = {c['id']: make_model(c) for c in configs}\n",
    "\n",
    "    # Inicializar warm start\n",
    "    for cid, model in models.items():\n",
    "        model.partial_fit(scaler.transform(X_train[:2]), y_train[:2], classes=np.array([0, 1]))\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        for cid, entry in active.items():\n",
    "            cfg = entry['config']\n",
    "            model = models[cid]\n",
    "            n = X_train.shape[0]\n",
    "            idx = np.random.permutation(n)\n",
    "            for start in range(0, n, cfg['batch_size']):\n",
    "                b = idx[start:start + cfg['batch_size']]\n",
    "                model.partial_fit(scaler.transform(X_train[b]), y_train[b])\n",
    "\n",
    "        if epoch % eval_interval == 0:\n",
    "            scores = []\n",
    "            for cid in list(active.keys()):\n",
    "                model = models[cid]\n",
    "                acc = accuracy_score(y_train, model.predict(scaler.transform(X_train)))\n",
    "                active[cid]['history'].append((epoch, acc))\n",
    "                scores.append((cid, acc))\n",
    "\n",
    "            # Eliminar la peor configuración si hay más de 2\n",
    "            if len(active) > 2:\n",
    "                worst = min(scores, key=lambda x: x[1])[0]\n",
    "                del active[worst]\n",
    "                print(f\"Epoch {epoch}: Eliminada la peor config {worst}\")\n",
    "\n",
    "    results = {}\n",
    "    for cid, entry in active.items():\n",
    "        model = models[cid]\n",
    "        results[cid] = {\n",
    "            'config': entry['config'],\n",
    "            'train_history': entry['history'],\n",
    "            'test_metrics': evaluate_model(model, scaler, X_val, y_val)\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# === Ejecución ===\n",
    "cfg_path = \"configs.json\"\n",
    "data_path = \"Data/Dataset_clean.csv\"\n",
    "\n",
    "# Cargar configuración y datos\n",
    "with open(cfg_path, \"r\") as f:\n",
    "    configs = json.load(f)['configs']\n",
    "\n",
    "df = load_data(data_path)\n",
    "X, y = preprocess(df)\n",
    "\n",
    "# División de datos 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1, stratify=y\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "results = run_training(configs, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Resultados finales\n",
    "print('\\n=== Resultados finales ===')\n",
    "for cid, res in results.items():\n",
    "    print(f\"\\nConfig {cid}:\")\n",
    "    print(json.dumps(res['test_metrics'], indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
